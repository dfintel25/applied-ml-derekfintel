{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc661ef5",
   "metadata": {},
   "source": [
    "# Lab 5: Ensemble ML, Spiral Project\n",
    "**Author:** Derek Fintel\n",
    "\n",
    "**Date:** April, 11th, 2025 \n",
    "\n",
    "**Objective:** Ensemble models combine the outputs of multiple models to improve predictive performance. Common types of ensemble models include:\n",
    "\n",
    "- Boosted Decision Trees – Models train sequentially, with each new tree correcting the errors of the previous one.\n",
    "- Random Forest – Multiple decision trees train in parallel, each on a random subset of the data, and their predictions are averaged.\n",
    "- Voting Classifier (Heterogeneous Models) – Combines different types of models (e.g., Decision Tree, SVM, and Neural Network) by taking the majority vote or average prediction.\n",
    "- Cross Validation – Divides data into multiple folds to improve the reliability of performance estimates.\n",
    "\n",
    "**Data Source:**\n",
    "We use the Wine Quality Dataset made available by the UCI Machine Learning Repository.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Wine+QualityLinks to an external site.\n",
    "\n",
    "Data originally published by:\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.  \n",
    "Modeling wine preferences by data mining from physicochemical properties.  \n",
    "In Decision Support Systems, Elsevier, 47(4):547–553, 2009.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a7248f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this project we utilize a a Wine Quality dataset to enable an ensemble model activity. \n",
    "\n",
    "This project is organized into the following Sections:\n",
    "- Section 0: Imports\n",
    "- Section 1: Load and Inspect the Data\n",
    "- Section 2: Prepare the Data\n",
    "- Section 3: Feature Selection and Justification\n",
    "- Section 4: Split the Data into Train and Test\n",
    "- Section 5: Evaluate Model Performance (Choose 2)\n",
    "- Section 6: Compare Results \n",
    "- Section 7. Conclusions and Insights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc158964",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdbbe5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b669a6",
   "metadata": {},
   "source": [
    "#### The dataset includes 11 physicochemical input variables (features):\n",
    "\n",
    "- fixed acidity          mostly tartaric acid\n",
    "- volatile acidity       mostly acetic acid (vinegar)\n",
    "- citric acid            can add freshness and flavor\n",
    "- residual sugar         remaining sugar after fermentation\n",
    "- chlorides              salt content\n",
    "- free sulfur dioxide    protects wine from microbes\n",
    "- total sulfur dioxide   sum of free and bound forms\n",
    "- density                related to sugar content\n",
    "- pH                     acidity level (lower = more acidic)\n",
    "- sulphates              antioxidant and microbial stabilizer\n",
    "- alcohol                % alcohol by volume\n",
    "\n",
    "The target variable is:\n",
    "- quality (integer score from 0 to 10, rated by wine tasters)\n",
    "\n",
    "We will simplify this target into three categories:\n",
    "- low (3–4), medium (5–6), high (7–8) to make classification feasible.\n",
    "- we will also make this numeric (we want both for clarity)\n",
    "The dataset contains 1599 samples and 12 columns (11 features + target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002b76e8",
   "metadata": {},
   "source": [
    "### Section 1. Load and Inspect the Data\n",
    "In this section we load the designated dataset and display the summary information and first 10 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9fa20480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset (download from UCI and save in the same folder)\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72c017",
   "metadata": {},
   "source": [
    "### Section 2. Prepare the Data\n",
    " In this section we will clean data, conduct feature engineering, perform encoding, split data, and execute helper functions\n",
    "\n",
    "1)  The functions below, temporarily take a \"q\" value and assign it parameters\n",
    " and return functions depending on values within the dataset. \n",
    "\n",
    "2) We then use this return data to formulate the a new column called \"quality_label\".\n",
    "\n",
    "3) Next we create another one used for modeling that will assign our quality value to a specific number range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e0cc8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function:\n",
    "# Takes one input, the quality (which we will temporarily name \"q\" while in the function)\n",
    "# And returns a string of the quality label (low, medium, high)\n",
    "# This function will be used to create the \"quality_label\" column\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "\n",
    "\n",
    "# Then, create a numeric column for modeling: 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "\n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4c0b7",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification\n",
    "In this section, we assign our feature & target variables for model training:\n",
    "\n",
    "X = \"quality\", \"quality_label\", & \"quality_numeric\". (Features)\n",
    "\n",
    "y = \"quality_numeric\" (Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "934424a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "# Target: quality_label (the new column we just created)\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde0cf3",
   "metadata": {},
   "source": [
    "## Section 4. Split the Data into Train and Test\n",
    "The code below splits train & test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b63ee638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size: (1279, 11)\n",
      "Test Size: (320, 11)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Train Size:\", X_train.shape)\n",
    "print(\"Test Size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45439350",
   "metadata": {},
   "source": [
    "## Section 5.  Evaluate Model Performance (Choose 2)\n",
    "Below is a list of  9 model variations. Choose two to focus on for your comparison. \n",
    "\n",
    "Models selected in this exercise are **BOLD.**\n",
    "\n",
    "Option\tModel Name\tNotes\n",
    "1) **Random Forest (100):**\tA strong baseline model using 100 decision trees.\n",
    "2) Random Forest (200, max_depth=10): Adds more trees, but limits tree depth to reduce overfitting.\n",
    "3) AdaBoost (100): Boosting method that focuses on correcting previous errors.\n",
    "4) AdaBoost (200, lr=0.5): More iterations and slower learning for better generalization.\n",
    "5) **Gradient Boosting (100):** Boosting approach using gradient descent.\n",
    "6) Voting (DT + SVM + NN): Combines diverse models by averaging their predictions.\n",
    "7) Voting (RF + LR + KNN): Another mix of different model types.\n",
    "8) Bagging (DT, 100): Builds many trees in parallel on different samples.\n",
    "9) MLP Classifier: A basic neural network with one hidden layer.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b33b2908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21419394",
   "metadata": {},
   "source": [
    "### Here we train our elected models:\n",
    "- Random Forest\n",
    "- Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "22a6c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 256   8]\n",
      " [  0  15  28]]\n",
      "Train Accuracy: 1.0000, Test Accuracy: 0.8875\n",
      "Train F1 Score: 1.0000, Test F1 Score: 0.8661\n",
      "\n",
      "Gradient Boosting (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# 1. Random Forest\n",
    "evaluate_model(\n",
    "    \"Random Forest (100)\",\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 2. Random Forest (200, max depth=10) \n",
    "#evaluate_model(\n",
    "#    \"Random Forest (200, max_depth=10)\",\n",
    "#    RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "#    X_train,\n",
    "#    y_train,\n",
    "#    X_test,\n",
    "#    y_test,\n",
    "#    results,\n",
    "#)\n",
    "\n",
    "# 3. AdaBoost \n",
    "#evaluate_model(\n",
    "#    \"AdaBoost (100)\",\n",
    "#    AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "#    X_train,\n",
    "#    y_train,\n",
    "#    X_test,\n",
    "#    y_test,\n",
    "#    results,\n",
    "#)\n",
    "\n",
    "# 4. AdaBoost (200, lr=0.5) \n",
    "#evaluate_model(\n",
    "#    \"AdaBoost (200, lr=0.5)\",\n",
    "#    AdaBoostClassifier(n_estimators=200, learning_rate=0.5, random_state=42),\n",
    "#    X_train,\n",
    "#    y_train,\n",
    "#    X_test,\n",
    "#    y_test,\n",
    "#    results,\n",
    "#)\n",
    "\n",
    "# 5. Gradient Boosting\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(\n",
    "        n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42\n",
    "    ),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# 6. Voting Classifier (DT, SVM, NN) \n",
    "#voting1 = VotingClassifier(\n",
    "#    estimators=[\n",
    "#        (\"DT\", DecisionTreeClassifier()),\n",
    "#        (\"SVM\", SVC(probability=True)),\n",
    "#        (\"NN\", MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000)),\n",
    "#    ],\n",
    "#    voting=\"soft\",\n",
    "#)\n",
    "#evaluate_model(\n",
    "#    \"Voting (DT + SVM + NN)\", voting1, X_train, y_train, X_test, y_test, results\n",
    "#)\n",
    "\n",
    "# 7. Voting Classifier (RF, LR, KNN) \n",
    "#voting2 = VotingClassifier(\n",
    "#    estimators=[\n",
    "#        (\"RF\", RandomForestClassifier(n_estimators=100)),\n",
    "#        (\"LR\", LogisticRegression(max_iter=1000)),\n",
    "#        (\"KNN\", KNeighborsClassifier()),\n",
    "#    ],\n",
    "#    voting=\"soft\",\n",
    "#)\n",
    "#evaluate_model(\n",
    "#    \"Voting (RF + LR + KNN)\", voting2, X_train, y_train, X_test, y_test, results\n",
    "#)\n",
    "\n",
    "# 8. Bagging \n",
    "#evaluate_model(\n",
    "#    \"Bagging (DT, 100)\",\n",
    "#    BaggingClassifier(\n",
    "#        estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42\n",
    "#    ),\n",
    "#    X_train,\n",
    "#    y_train,\n",
    "#    X_test,\n",
    "#    y_test,\n",
    "#    results,\n",
    "#)\n",
    "\n",
    "# 9. MLP Classifier \n",
    "#evaluate_model(\n",
    "#    \"MLP Classifier\",\n",
    "#    MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "#    X_train,\n",
    "#    y_train,\n",
    "#    X_test,\n",
    "#    y_test,\n",
    "#    results,\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a82625",
   "metadata": {},
   "source": [
    "### Section 6. Compare Results \n",
    "Here we utilize dataframes to pull the results and print them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db72cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest (100)</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.88750</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.866056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting (100)</td>\n",
       "      <td>0.960125</td>\n",
       "      <td>0.85625</td>\n",
       "      <td>0.95841</td>\n",
       "      <td>0.841106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train Accuracy  Test Accuracy  Train F1   Test F1\n",
       "0      Random Forest (100)        1.000000        0.88750   1.00000  0.866056\n",
       "1  Gradient Boosting (100)        0.960125        0.85625   0.95841  0.841106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a table of results \n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by 'Test Accuracy' in descending order\n",
    "df_sorted = results_df.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\nSummary of All Models:\")\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7332d24",
   "metadata": {},
   "source": [
    "### Section 7. Conclusions and Insights\n",
    "Using both your results and the results from others, which options are performing well and why do you think so. \n",
    "\n",
    "This is your value as an analyst - narrate your story, link to other notebooks, provide a comprehensive view of what you feel is the best model for predicting quality in red wine. Base all your reasoning on data. Feel free to tune parameters if you like.  Discuss the types of models and why you think some seem to be more helpful. List the next steps you'd like to try if you were in a competition to build the best predictor. \n",
    "\n",
    "Don't just copy code and don't just copy AI insights - use them to learn, but we all get them for free. Use all your tools to provide your own unique value and insights. Professional communication skills are critical. Evaluate your work in the context of others - how well can you craft a unique data story and present a compelling project to your clients / readers / self. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
